{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Leer todos los archivos y mergearlos en un solo dataset\n",
    "def cargar_y_combinar_datos():\n",
    "    # Cargar archivos\n",
    "    sell_in = pd.read_csv('sell-in.txt', sep='\\t')\n",
    "    stocks = pd.read_csv('tb_stocks.txt', sep='\\t')\n",
    "    productos = pd.read_csv('tb_productos.txt', sep='\\t')\n",
    "    #drop duplicates in productos\n",
    "    productos = productos.drop_duplicates(subset=['product_id'])\n",
    "    # drop column description from productos\n",
    "    productos = productos.drop(columns=['descripcion'], errors='ignore')\n",
    "    \n",
    "    # Unir datasets\n",
    "    df = sell_in.merge(stocks, on=['periodo', 'product_id'], how='left')\n",
    "    df = df.merge(productos, on='product_id', how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def cargar_datos():\n",
    "    df = pd.read_csv('sell-in.txt', sep='\\t')\n",
    "    return df\n",
    "\n",
    "def combinar_datos(df):\n",
    "    stocks = pd.read_csv('tb_stocks.txt', sep='\\t')\n",
    "    productos = pd.read_csv('tb_productos.txt', sep='\\t')\n",
    "    #drop duplicates in productos\n",
    "    productos = productos.drop_duplicates(subset=['product_id'])\n",
    "    # drop column description from productos\n",
    "    productos = productos.drop(columns=['descripcion'], errors='ignore')\n",
    "\n",
    "    # Unir datasets\n",
    "    df = df.merge(stocks, on=['periodo', 'product_id'], how='left')\n",
    "    df = df.merge(productos, on='product_id', how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# 2) Transformar periodo en date\n",
    "def transformar_periodo(df):\n",
    "    df['fecha'] = pd.to_datetime(df['periodo'].astype(str), format='%Y%m')\n",
    "    return df\n",
    "\n",
    "\n",
    "# 3) Rellenar datos faltantes para series temporales\n",
    "def completar_series_temporales(df):\n",
    "    import pandas as pd\n",
    "\n",
    "    # Asegurar que 'fecha' es Period[M]\n",
    "    df['fecha'] = df['fecha'].astype('period[M]')\n",
    "    # ordeno por fecha\n",
    "    df = df.sort_values(by=['product_id', 'customer_id', 'fecha'])\n",
    "\n",
    "    columnas_forward_fill = ['plan_precios_cuidados', 'stock_final', 'cat1', 'cat2', 'cat3', 'brand', 'sku_size']\n",
    "    columnas_a_rellenar = ['cust_request_qty', 'cust_request_tn', 'tn']\n",
    "\n",
    "    ## 1. Obtener todos los valores únicos de producto, cliente y rango de fechas completo\n",
    "    all_product_customer = df[['product_id', 'customer_id']].drop_duplicates()\n",
    "    fecha_min = df['fecha'].min()\n",
    "    fecha_max = df['fecha'].max()\n",
    "    todas_fechas = pd.period_range(start=fecha_min, end=fecha_max, freq='M')\n",
    "\n",
    "    # 2. Crear el cartesian product de (product_id, customer_id, fecha)\n",
    "    full_index = (\n",
    "        all_product_customer\n",
    "        .assign(key=1)\n",
    "        .merge(pd.DataFrame({'fecha': todas_fechas, 'key': 1}), on='key')\n",
    "        .drop('key', axis=1)\n",
    "    )\n",
    "\n",
    "    # 3. Merge con el dataframe original para obtener datos completos\n",
    "    df_full = full_index.merge(df, on=['product_id', 'customer_id', 'fecha'], how='left')\n",
    "\n",
    "    # 4. Ordenar correctamente\n",
    "    df_full = df_full.sort_values(['product_id', 'customer_id', 'fecha'])\n",
    "\n",
    "    # 5. Forward fill para columnas deseadas (por grupo)\n",
    "    df_full[columnas_forward_fill] = (\n",
    "        df_full\n",
    "        .groupby(['product_id', 'customer_id'])[columnas_forward_fill]\n",
    "        .ffill()\n",
    "    )\n",
    "\n",
    "    # 6. Rellenar valores faltantes de demanda con 0\n",
    "    df_full[columnas_a_rellenar] = df_full[columnas_a_rellenar].fillna(0)\n",
    "\n",
    "    # drop rows where precios_cuidados es nan porque significa que son fechas que no existia ese cliente\n",
    "    df_full = df_full.dropna(subset=['plan_precios_cuidados'])\n",
    "\n",
    "    return df_full.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#4) Crear variable objetivo (t+2)\n",
    "def crear_variable_objetivo(df):\n",
    "    # Ordenamos por producto, cliente y fecha\n",
    "    df = df.sort_values(['product_id', 'customer_id', 'fecha'])\n",
    "    \n",
    "    ## Creamos un dataframe para el shift\n",
    "    #df_shift = df[['product_id', 'customer_id', 'fecha', 'tn']].copy()\n",
    "    \n",
    "    # Shift de 2 meses para el target\n",
    "    #df_shift['fecha_target'] = df_shift['fecha'] + pd.DateOffset(months=2)\n",
    "    #df_shift.rename(columns={'tn': 'target', 'fecha': 'fecha_origen'}, inplace=True)\n",
    "    \n",
    "    ## Unimos con el dataframe original\n",
    "    #df = df.merge(df_shift[['product_id', 'customer_id', 'fecha_target', 'target']], \n",
    "    #             left_on=['product_id', 'customer_id', 'fecha'], \n",
    "    #             right_on=['product_id', 'customer_id', 'fecha_target'], \n",
    "    #             how='left')\n",
    "    # el codigo de arriba esta mal, hay que hacer el shift 2 (ya que esta rellenado con 0s), fecha_target no es necesario\n",
    "    df['target'] = df.groupby(['product_id', 'customer_id'])['tn'].shift(-2)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# 5) Crear features para el modelo\n",
    "def crear_features(df, lag_columns=[\"tn\", \"cust_request_qty\"]):\n",
    "    # Extraer mes del año\n",
    "    df['mes'] = df['fecha'].dt.month\n",
    "    df[\"year\"] = df[\"fecha\"].dt.year\n",
    "    \n",
    "\n",
    "    # ratio between cust_request_qty and cust_request_tn (fill Na with 0)\n",
    "    df[\"cust_request_ratio\"] = df[\"cust_request_qty\"] / df[\"cust_request_tn\"]\n",
    "    df[\"cust_request_ratio\"] = df[\"cust_request_ratio\"].fillna(0)\n",
    "\n",
    "    # Crear lags (valores anteriores)\n",
    "    for i in [1,2,6,12]:  # Lags de 1 a 6 meses\n",
    "        print(f\"Creando lag {i}\")\n",
    "        for col in lag_columns:\n",
    "            df[f'{col}_lag_{i}'] = df.groupby(['product_id', 'customer_id'])[col].shift(i)\n",
    "    \n",
    "    # Crear medias móviles\n",
    "    for n in [3, 6]:  # Medias de 3, 6 y 12 meses\n",
    "        print(f\"Creando media {n}\")\n",
    "        for col in lag_columns:\n",
    "            df[f'{col}_media_{n}'] = df.groupby(['product_id', 'customer_id'])[col].transform(\n",
    "                lambda x: x.rolling(window=n, min_periods=n).mean()\n",
    "            )\n",
    "    \n",
    "    # Crear máximos y mínimos móviles\n",
    "    for n in [3]:\n",
    "        for col in lag_columns:\n",
    "            print(f\"Creando max {n}\")\n",
    "            df[f'{col}_max_{n}'] = df.groupby(['product_id', 'customer_id'])[col].transform(\n",
    "                lambda x: x.rolling(window=n, min_periods=n).max()\n",
    "            )\n",
    "            print(f\"Creando min {n}\")\n",
    "            df[f'{col}_min_{n}'] = df.groupby(['product_id', 'customer_id'])[col].transform(\n",
    "                lambda x: x.rolling(window=n, min_periods=n).min()\n",
    "            )\n",
    "    \n",
    "    # Tendencia (diferencia entre media de 3 y 6 meses)\n",
    "    for col in lag_columns:\n",
    "        df[f'{col}_tendencia'] = df[f'{col}_media_3'] - df[f'{col}_media_6']\n",
    "    \n",
    "    for col in lag_columns:\n",
    "        df[\"stock_ratio\"] = df[\"stock_final\"] / (df[f\"{col}_media_3\"] + 1)  # +1 para evitar división por cero\n",
    "    \n",
    "    return df \n",
    "\n",
    "\n",
    "#6) Separar el dataset\n",
    "def separar_dataset(df):\n",
    "    fechas_ordenadas = sorted(df['fecha'].unique())\n",
    "    ultima_fecha = fechas_ordenadas[-1]\n",
    "    penultima_fecha = fechas_ordenadas[-3]\n",
    "    antepenultima_fecha = fechas_ordenadas[-4]\n",
    "    \n",
    "    # Dataset para predicción final (Kaggle)\n",
    "    kaggle_pred = df[df['fecha'] == ultima_fecha].copy()\n",
    "    \n",
    "    # Dataset de test\n",
    "    test = df[df['fecha'] == penultima_fecha].copy()\n",
    "    \n",
    "    # Dataset de evaluación\n",
    "    eval_data = df[df['fecha'] == antepenultima_fecha].copy()\n",
    "    \n",
    "    # Dataset de entrenamiento\n",
    "    train = df[(df['fecha'] < antepenultima_fecha) & (df['fecha'] != ultima_fecha)].copy()\n",
    "    \n",
    "    return train, eval_data, test, kaggle_pred\n",
    "\n",
    "\n",
    "\n",
    "# Creamos una clase para la métrica personalizada que necesita acceso a product_id\n",
    "class CustomMetric:\n",
    "    def __init__(self, df_eval, product_id_col='product_id'):\n",
    "        self.df_eval = df_eval\n",
    "        self.product_id_col = product_id_col\n",
    "    \n",
    "    def __call__(self, preds, train_data):\n",
    "        labels = train_data.get_label()\n",
    "        df_temp = self.df_eval.copy()\n",
    "        df_temp['preds'] = preds\n",
    "        df_temp['labels'] = labels\n",
    "        \n",
    "        # Agrupar por product_id y calcular el error\n",
    "        por_producto = df_temp.groupby(self.product_id_col).agg({'labels': 'sum', 'preds': 'sum'})\n",
    "        \n",
    "        # Calcular el error personalizado\n",
    "        error = np.sum(np.abs(por_producto['labels'] - por_producto['preds'])) / np.sum(por_producto['labels'])\n",
    "        \n",
    "        # LightGBM espera que el segundo valor sea mayor cuando el modelo es mejor\n",
    "        return 'custom_error', error, False\n",
    "\n",
    "def entrenar_modelo(X_train, y_train, X_eval, y_eval, df_eval):\n",
    "    cat_features = [col for col in X_train.columns if X_train[col].dtype.name == 'category']\n",
    "    train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features)\n",
    "    eval_data = lgb.Dataset(X_eval, label=y_eval, reference=train_data, categorical_feature=cat_features)\n",
    "    \n",
    "    df_eval_metric = df_eval[['product_id']].copy()\n",
    "    custom_metric = CustomMetric(df_eval_metric)\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 31,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    callbacks = [\n",
    "        lgb.early_stopping(50),\n",
    "        lgb.log_evaluation(100)\n",
    "    ]\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[eval_data],\n",
    "        feval=custom_metric,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "# 8) Evaluar el modelo en test\n",
    "def evaluar_modelo(model, X_test, test_df):\n",
    "    # Predicciones\n",
    "    predictions = model.predict(X_test)\n",
    "    test_df['predictions'] = predictions\n",
    "    \n",
    "    # Error por producto\n",
    "    product_actual = test_df.groupby('product_id')['target'].sum()\n",
    "    product_pred = test_df.groupby('product_id')['predictions'].sum()\n",
    "    \n",
    "    # Crear DataFrame de evaluación\n",
    "    eval_df = pd.DataFrame({\n",
    "        'product_id': product_actual.index,\n",
    "        'tn_real': product_actual.values,\n",
    "        'tn_predicha': product_pred.values\n",
    "    })\n",
    "    \n",
    "    # Calcular el error personalizado\n",
    "    total_error = np.sum(np.abs(eval_df['tn_real'] - eval_df['tn_predicha'])) / np.sum(eval_df['tn_real'])\n",
    "    \n",
    "    print(f\"Error en test: {total_error:.4f}\")\n",
    "    print(\"\\nTop 5 productos con mayor error absoluto:\")\n",
    "    eval_df['error_absoluto'] = np.abs(eval_df['tn_real'] - eval_df['tn_predicha'])\n",
    "    print(eval_df.sort_values('error_absoluto', ascending=False).head())\n",
    "    \n",
    "    return eval_df, total_error\n",
    "\n",
    "\n",
    "# Función para optimizar el dataframe y reducir memoria\n",
    "def optimizar_dataframe(df):\n",
    "    # Copia para no modificar el original\n",
    "    df_optimizado = df.copy()\n",
    "    \n",
    "    # Convertir float64 a float32\n",
    "    for col in df_optimizado.select_dtypes(include=['float64']).columns:\n",
    "        df_optimizado[col] = df_optimizado[col].astype('float32')\n",
    "    \n",
    "    # Optimizar fecha - usar periodo_date con solo mes y año\n",
    "    if 'fecha' in df_optimizado.columns:\n",
    "        # Usar un formato más ligero para fecha (solo mes y año)\n",
    "        df_optimizado['fecha'] = pd.PeriodIndex(df_optimizado['fecha'], freq='M')\n",
    "    \n",
    "    # Nota: Mantener 'periodo' ya que se usa para operaciones posteriores\n",
    "    # pero se podría eliminar al final del proceso si ya no es necesario\n",
    "    \n",
    "    # Convertir customer_id y product_id a int32\n",
    "    if 'customer_id' in df_optimizado.columns:\n",
    "        df_optimizado['customer_id'] = df_optimizado['customer_id'].astype(\"uint32\")\n",
    "    \n",
    "    if 'product_id' in df_optimizado.columns:\n",
    "        df_optimizado['product_id'] = df_optimizado['product_id'].astype(\"uint32\")\n",
    "    \n",
    "    # Convertir plan_precios_cuidados a categoría\n",
    "    if 'plan_precios_cuidados' in df_optimizado.columns:\n",
    "        df_optimizado['plan_precios_cuidados'] = df_optimizado['plan_precios_cuidados'].astype('category')\n",
    "    \n",
    "    # Convertir cust_request_qty a int32 si es posible\n",
    "    if 'cust_request_qty' in df_optimizado.columns:\n",
    "        if df_optimizado['cust_request_qty'].dropna().apply(lambda x: float(x).is_integer()).all():\n",
    "            df_optimizado['cust_request_qty'] = df_optimizado['cust_request_qty'].fillna(0).astype('int32')\n",
    "        else:\n",
    "            df_optimizado['cust_request_qty'] = df_optimizado['cust_request_qty'].astype('float32')\n",
    "    \n",
    "    # Convertir columnas de objeto a categorías\n",
    "    for col in df_optimizado.select_dtypes(include=['object']).columns:\n",
    "        df_optimizado[col] = df_optimizado[col].astype('category')\n",
    "    \n",
    "    # Mostrar información sobre la reducción de memoria\n",
    "    print(f\"Memoria antes de optimizar: {df.memory_usage().sum() / 1024**2:.2f} MB\")\n",
    "    print(f\"Memoria después de optimizar: {df_optimizado.memory_usage().sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    return df_optimizado\n",
    "\n",
    "\n",
    "def completar_series_temporales_v1(df):\n",
    "    \"\"\"\n",
    "    Esta version completa las series temporales de productos y clientes cuando AMBOS estaban activos. \n",
    "    Entiendo ACTIVOS como los periodos que son igual o mayores a la primer fecha de venta de cada cliente y producto.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # Asegurar que 'fecha' es Period[M]\n",
    "    df['fecha'] = df['fecha'].astype('period[M]')\n",
    "\n",
    "    columnas_forward_fill = ['plan_precios_cuidados', 'stock_final', 'cat1', 'cat2', 'cat3', 'brand', 'sku_size']\n",
    "    columnas_a_rellenar = ['cust_request_qty', 'cust_request_tn', 'tn']\n",
    "\n",
    "    # 1. Fecha mínima de aparición por cliente y producto\n",
    "    fecha_ini_clientes = df.groupby('customer_id')['fecha'].min().reset_index().rename(columns={'fecha': 'fecha_ini_c'})\n",
    "    fecha_ini_productos = df.groupby('product_id')['fecha'].min().reset_index().rename(columns={'fecha': 'fecha_ini_p'})\n",
    "\n",
    "    # 2. Rango completo de fechas\n",
    "    fechas = pd.period_range(df['fecha'].min(), df['fecha'].max(), freq='M')\n",
    "    fechas_df = pd.DataFrame({'fecha': fechas})\n",
    "\n",
    "    # 3. Combinar clientes x fechas >= fecha_ini\n",
    "    clientes_fechas = fecha_ini_clientes.merge(fechas_df, how='cross')\n",
    "    clientes_fechas = clientes_fechas[clientes_fechas['fecha'] >= clientes_fechas['fecha_ini_c']]\n",
    "    clientes_fechas = clientes_fechas[['customer_id', 'fecha']]\n",
    "\n",
    "    productos_fechas = fecha_ini_productos.merge(fechas_df, how='cross')\n",
    "    productos_fechas = productos_fechas[productos_fechas['fecha'] >= productos_fechas['fecha_ini_p']]\n",
    "    productos_fechas = productos_fechas[['product_id', 'fecha']]\n",
    "\n",
    "    # 4. Intersección cliente-producto donde ambos ya eran activos (pero sin cortar por fecha final)\n",
    "    posibles_combinaciones = productos_fechas.merge(clientes_fechas, on='fecha', how='inner')\n",
    "\n",
    "    # 5. Merge con datos originales\n",
    "    df_full = posibles_combinaciones.merge(df, on=['product_id', 'customer_id', 'fecha'], how='left')\n",
    "\n",
    "    # 6. Ordenar\n",
    "    df_full = df_full.sort_values(['product_id', 'customer_id', 'fecha'])\n",
    "\n",
    "    # 7. Forward fill por grupo\n",
    "    df_full[columnas_forward_fill] = (\n",
    "        df_full.groupby(['product_id', 'customer_id'])[columnas_forward_fill].ffill()\n",
    "    )\n",
    "\n",
    "    # 8. Completar demanda con 0\n",
    "    df_full[columnas_a_rellenar] = df_full[columnas_a_rellenar].fillna(0)\n",
    "\n",
    "    # dropea las rows donde el el producto no existia\n",
    "    stocks = pd.read_csv('tb_stocks.txt', sep='\\t')\n",
    "    productos = pd.read_csv('tb_productos.txt', sep='\\t')\n",
    "    #drop duplicates in productos\n",
    "    productos = productos.drop_duplicates(subset=['product_id'])\n",
    "    productos = productos.drop(columns=['descripcion'], errors='ignore')\n",
    "\n",
    "    # Unir datasets\n",
    "    # drop stock_final y cat1\tcat2\tcat3\tbrand\tsku_size\tya que se hacen en el merge\n",
    "    df_full = df_full.drop(columns=['stock_final', 'cat1', 'cat2', 'cat3', 'brand', 'sku_size'])\n",
    "    df_full = df_full.merge(stocks, on=['periodo', 'product_id'], how='left')\n",
    "    df_full = df_full.merge(productos, on='product_id', how='left')\n",
    "    \n",
    "    return df_full.reset_index(drop=True)\n",
    "\n",
    "def completar_series_temporales_v2(df):\n",
    "    \"\"\"\n",
    "    Esta versión completa las series temporales de productos y clientes cuando AMBOS estaban activos.\n",
    "    Se considera 'ACTIVO' el periodo entre la primera y última fecha de venta de cada cliente y producto.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # Asegurar que 'fecha' es Period[M]\n",
    "    df['fecha'] = pd.to_datetime(df['periodo'].astype(str), format='%Y%m')\n",
    "    df['fecha'] = df['fecha'].astype('period[M]')\n",
    "\n",
    "    columnas_forward_fill = ['plan_precios_cuidados']\n",
    "    columnas_a_rellenar = ['cust_request_qty', 'cust_request_tn', 'tn', 'plan_precios_cuidados']\n",
    "\n",
    "    # 1. Fecha mínima y máxima de aparición por cliente y producto\n",
    "    fechas_clientes = df.groupby('customer_id')['fecha'].agg(fecha_ini_c='min', fecha_fin_c='max').reset_index()\n",
    "    fechas_productos = df.groupby('product_id')['fecha'].agg(fecha_ini_p='min', fecha_fin_p='max').reset_index()\n",
    "\n",
    "    # los clientes donde la fecha de fin sea menor a 2019-09 lo paso a 2020-01\n",
    "    fechas_clientes.loc[fechas_clientes['fecha_fin_c'] >= '2019-09', 'fecha_fin_c'] = '2020-01'\n",
    "\n",
    "\n",
    "    # print number of fechas that are 2020-01\n",
    "    print(f\"Número de clientes con fecha_fin_c en 2020-01: {fechas_clientes[fechas_clientes['fecha_fin_c'] == '2020-01'].shape[0]}\")\n",
    "\n",
    "    # 2. Rango completo de fechas\n",
    "    fechas = pd.period_range(df['fecha'].min(), df['fecha'].max(), freq='M')\n",
    "    fechas_df = pd.DataFrame({'fecha': fechas})\n",
    "\n",
    "    # 3. Crear combinación cliente-fechas activas\n",
    "    clientes_fechas = fechas_clientes.merge(fechas_df, how='cross')\n",
    "    clientes_fechas = clientes_fechas[\n",
    "\n",
    "        (clientes_fechas['fecha'] >= clientes_fechas['fecha_ini_c']) &\n",
    "        (clientes_fechas['fecha'] <= clientes_fechas['fecha_fin_c'])\n",
    "    ][['customer_id', 'fecha']]\n",
    "\n",
    "    # 4. Crear combinación producto-fechas activas\n",
    "    productos_fechas = fechas_productos.merge(fechas_df, how='cross')\n",
    "    productos_fechas = productos_fechas[\n",
    "        (productos_fechas['fecha'] >= productos_fechas['fecha_ini_p']) &\n",
    "        (productos_fechas['fecha'] <= productos_fechas['fecha_fin_p'])\n",
    "    ][['product_id', 'fecha']]\n",
    "\n",
    "    # 5. Intersección cliente-producto donde ambos eran activos\n",
    "    posibles_combinaciones = productos_fechas.merge(clientes_fechas, on='fecha', how='inner')\n",
    "\n",
    "    # 6. Merge con datos originales\n",
    "    df_full = posibles_combinaciones.merge(df, on=['product_id', 'customer_id', 'fecha'], how='left')\n",
    "\n",
    "    # 7. Ordenar\n",
    "    df_full = df_full.sort_values(['product_id', 'customer_id', 'fecha'])\n",
    "\n",
    "    # 8. Forward fill por grupo\n",
    "    #df_full[columnas_forward_fill] = (\n",
    "    #    df_full.groupby(['product_id', 'customer_id'])[columnas_forward_fill].ffill()\n",
    "    #)\n",
    "\n",
    "    # 9. Completar demanda con 0\n",
    "    df_full[columnas_a_rellenar] = df_full[columnas_a_rellenar].fillna(0)\n",
    "\n",
    "    return df_full.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201701</td>\n",
       "      <td>10032</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.13628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201701</td>\n",
       "      <td>10217</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>0.03028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201701</td>\n",
       "      <td>10125</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.02271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201701</td>\n",
       "      <td>10012</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>1.54452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty  \\\n",
       "0   201701        10234       20524                      0                 2   \n",
       "1   201701        10032       20524                      0                 1   \n",
       "2   201701        10217       20524                      0                 1   \n",
       "3   201701        10125       20524                      0                 1   \n",
       "4   201701        10012       20524                      0                11   \n",
       "\n",
       "   cust_request_tn       tn  \n",
       "0          0.05300  0.05300  \n",
       "1          0.13628  0.13628  \n",
       "2          0.03028  0.03028  \n",
       "3          0.02271  0.02271  \n",
       "4          1.54452  1.54452  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cargar_datos()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>fecha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201701</td>\n",
       "      <td>10032</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201701</td>\n",
       "      <td>10217</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201701</td>\n",
       "      <td>10125</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201701</td>\n",
       "      <td>10012</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty  \\\n",
       "0   201701        10234       20524                      0                 2   \n",
       "1   201701        10032       20524                      0                 1   \n",
       "2   201701        10217       20524                      0                 1   \n",
       "3   201701        10125       20524                      0                 1   \n",
       "4   201701        10012       20524                      0                11   \n",
       "\n",
       "   cust_request_tn       tn      fecha  \n",
       "0          0.05300  0.05300 2017-01-01  \n",
       "1          0.13628  0.13628 2017-01-01  \n",
       "2          0.03028  0.03028 2017-01-01  \n",
       "3          0.02271  0.02271 2017-01-01  \n",
       "4          1.54452  1.54452 2017-01-01  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = transformar_periodo(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de clientes con fecha_fin_c en 2020-01: 500\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15643071 entries, 0 to 15643070\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Dtype    \n",
      "---  ------                 -----    \n",
      " 0   product_id             int64    \n",
      " 1   fecha                  period[M]\n",
      " 2   customer_id            int64    \n",
      " 3   periodo                float64  \n",
      " 4   plan_precios_cuidados  float64  \n",
      " 5   cust_request_qty       float64  \n",
      " 6   cust_request_tn        float64  \n",
      " 7   tn                     float64  \n",
      "dtypes: float64(5), int64(2), period[M](1)\n",
      "memory usage: 954.8 MB\n"
     ]
    }
   ],
   "source": [
    "df = completar_series_temporales_v2(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>fecha</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>10001</td>\n",
       "      <td>201701.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>99.43861</td>\n",
       "      <td>99.43861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>10001</td>\n",
       "      <td>201702.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>198.84365</td>\n",
       "      <td>198.84365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>10001</td>\n",
       "      <td>201703.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>92.46537</td>\n",
       "      <td>92.46537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>10001</td>\n",
       "      <td>201704.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.29728</td>\n",
       "      <td>13.29728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-05</td>\n",
       "      <td>10001</td>\n",
       "      <td>201705.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>101.20711</td>\n",
       "      <td>101.00563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15643066</th>\n",
       "      <td>21299</td>\n",
       "      <td>2017-08</td>\n",
       "      <td>10605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15643067</th>\n",
       "      <td>21299</td>\n",
       "      <td>2017-08</td>\n",
       "      <td>10611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15643068</th>\n",
       "      <td>21299</td>\n",
       "      <td>2017-08</td>\n",
       "      <td>10614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15643069</th>\n",
       "      <td>21299</td>\n",
       "      <td>2017-08</td>\n",
       "      <td>10615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15643070</th>\n",
       "      <td>21299</td>\n",
       "      <td>2017-08</td>\n",
       "      <td>10630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15643071 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          product_id    fecha  customer_id   periodo  plan_precios_cuidados  \\\n",
       "0              20001  2017-01        10001  201701.0                    0.0   \n",
       "1              20001  2017-02        10001  201702.0                    0.0   \n",
       "2              20001  2017-03        10001  201703.0                    0.0   \n",
       "3              20001  2017-04        10001  201704.0                    0.0   \n",
       "4              20001  2017-05        10001  201705.0                    0.0   \n",
       "...              ...      ...          ...       ...                    ...   \n",
       "15643066       21299  2017-08        10605       NaN                    0.0   \n",
       "15643067       21299  2017-08        10611       NaN                    0.0   \n",
       "15643068       21299  2017-08        10614       NaN                    0.0   \n",
       "15643069       21299  2017-08        10615       NaN                    0.0   \n",
       "15643070       21299  2017-08        10630       NaN                    0.0   \n",
       "\n",
       "          cust_request_qty  cust_request_tn         tn  \n",
       "0                     11.0         99.43861   99.43861  \n",
       "1                     23.0        198.84365  198.84365  \n",
       "2                     33.0         92.46537   92.46537  \n",
       "3                      8.0         13.29728   13.29728  \n",
       "4                     15.0        101.20711  101.00563  \n",
       "...                    ...              ...        ...  \n",
       "15643066               0.0          0.00000    0.00000  \n",
       "15643067               0.0          0.00000    0.00000  \n",
       "15643068               0.0          0.00000    0.00000  \n",
       "15643069               0.0          0.00000    0.00000  \n",
       "15643070               0.0          0.00000    0.00000  \n",
       "\n",
       "[15643071 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combinar_datos(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memoria antes de optimizar: 1670.86 MB\n",
      "Memoria después de optimizar: 671.33 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15643071 entries, 0 to 15643070\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Dtype    \n",
      "---  ------                 -----    \n",
      " 0   product_id             uint32   \n",
      " 1   fecha                  period[M]\n",
      " 2   customer_id            uint32   \n",
      " 3   periodo                float32  \n",
      " 4   plan_precios_cuidados  category \n",
      " 5   cust_request_qty       int32    \n",
      " 6   cust_request_tn        float32  \n",
      " 7   tn                     float32  \n",
      " 8   stock_final            float32  \n",
      " 9   cat1                   category \n",
      " 10  cat2                   category \n",
      " 11  cat3                   category \n",
      " 12  brand                  category \n",
      " 13  sku_size               float32  \n",
      "dtypes: category(5), float32(5), int32(1), period[M](1), uint32(2)\n",
      "memory usage: 671.3 MB\n"
     ]
    }
   ],
   "source": [
    "df = optimizar_dataframe(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardo el df intermedio como parquet para que conserve el tipo de dato\n",
    "# paso plan_precios_cuidados a booleano donde 1 es True y 0 es False\n",
    "#df['plan_precios_cuidados'] = df['plan_precios_cuidados'].astype(np.uint8)\n",
    "#df['plan_precios_cuidados'] = df['plan_precios_cuidados'] > 0\n",
    "df.to_parquet('df_intermedio.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20001, 20002, 20003, 20004, 20005, 20006, 20007, 20008, 20009,\n",
       "       20010, 20011, 20012, 20013, 20014, 20015, 20016, 20017, 20018,\n",
       "       20019, 20020, 20021, 20022, 20023, 20024, 20025, 20026, 20027,\n",
       "       20028, 20029, 20030, 20031, 20032, 20033, 20035, 20037, 20038,\n",
       "       20039, 20041, 20042, 20043, 20044, 20045, 20046, 20047, 20049,\n",
       "       20050, 20051, 20052, 20053, 20054, 20055, 20056, 20057, 20058,\n",
       "       20059, 20061, 20062, 20063, 20065, 20066, 20067, 20068, 20069,\n",
       "       20070, 20071, 20072, 20073, 20074, 20075, 20076, 20077, 20079,\n",
       "       20080, 20081, 20082, 20084, 20085, 20086, 20087, 20089, 20090,\n",
       "       20091, 20092, 20093, 20094, 20095, 20096, 20097, 20099, 20100,\n",
       "       20101, 20102, 20103, 20106, 20107, 20108, 20109, 20111, 20112,\n",
       "       20114, 20116, 20117, 20118, 20119, 20120, 20121, 20122, 20123,\n",
       "       20124, 20125, 20126, 20127, 20129, 20130, 20132, 20133, 20134,\n",
       "       20135, 20137, 20138, 20139, 20140, 20142, 20143, 20144, 20145,\n",
       "       20146, 20148, 20150, 20151, 20152, 20153, 20155, 20157, 20158,\n",
       "       20159, 20160, 20161, 20162, 20164, 20166, 20167, 20168, 20170,\n",
       "       20174, 20175, 20176, 20177, 20179, 20180, 20181, 20182, 20183,\n",
       "       20184, 20187, 20188, 20189, 20192, 20193, 20196, 20197, 20198,\n",
       "       20200, 20201, 20202, 20203, 20205, 20206, 20207, 20208, 20209,\n",
       "       20210, 20211, 20212, 20213, 20215, 20216, 20218, 20219, 20220,\n",
       "       20222, 20224, 20225, 20226, 20227, 20228, 20230, 20231, 20232,\n",
       "       20233, 20234, 20235, 20236, 20237, 20238, 20239, 20240, 20241,\n",
       "       20242, 20244, 20246, 20249, 20251, 20252, 20253, 20254, 20255,\n",
       "       20256, 20257, 20259, 20261, 20262, 20263, 20264, 20265, 20266,\n",
       "       20267, 20268, 20269, 20270, 20271, 20272, 20273, 20275, 20276,\n",
       "       20277, 20278, 20280, 20281, 20282, 20283, 20284, 20285, 20286,\n",
       "       20288, 20289, 20290, 20291, 20292, 20295, 20296, 20297, 20298,\n",
       "       20299, 20300, 20301, 20302, 20303, 20304, 20305, 20306, 20307,\n",
       "       20309, 20310, 20311, 20313, 20314, 20315, 20316, 20317, 20319,\n",
       "       20320, 20321, 20322, 20323, 20324, 20325, 20326, 20327, 20328,\n",
       "       20329, 20330, 20332, 20334, 20335, 20336, 20337, 20338, 20340,\n",
       "       20341, 20342, 20343, 20344, 20346, 20348, 20349, 20350, 20351,\n",
       "       20352, 20353, 20354, 20355, 20356, 20357, 20358, 20359, 20361,\n",
       "       20362, 20364, 20365, 20366, 20367, 20368, 20372, 20375, 20377,\n",
       "       20378, 20379, 20380, 20381, 20382, 20383, 20384, 20385, 20386,\n",
       "       20387, 20388, 20389, 20390, 20395, 20396, 20398, 20400, 20401,\n",
       "       20402, 20403, 20404, 20406, 20407, 20408, 20409, 20410, 20411,\n",
       "       20414, 20415, 20416, 20417, 20418, 20419, 20421, 20422, 20424,\n",
       "       20426, 20428, 20429, 20432, 20433, 20434, 20438, 20440, 20442,\n",
       "       20443, 20447, 20449, 20450, 20453, 20456, 20458, 20459, 20460,\n",
       "       20463, 20464, 20465, 20466, 20469, 20470, 20473, 20474, 20476,\n",
       "       20477, 20478, 20479, 20480, 20481, 20482, 20483, 20484, 20488,\n",
       "       20490, 20491, 20495, 20496, 20497, 20500, 20502, 20503, 20505,\n",
       "       20508, 20509, 20510, 20513, 20514, 20517, 20520, 20521, 20522,\n",
       "       20523, 20524, 20525, 20526, 20527, 20530, 20531, 20532, 20536,\n",
       "       20537, 20538, 20539, 20540, 20541, 20542, 20544, 20547, 20548,\n",
       "       20549, 20551, 20552, 20553, 20555, 20558, 20559, 20560, 20561,\n",
       "       20563, 20565, 20567, 20568, 20569, 20570, 20571, 20572, 20574,\n",
       "       20575, 20576, 20577, 20578, 20579, 20580, 20583, 20585, 20586,\n",
       "       20588, 20589, 20592, 20593, 20596, 20597, 20599, 20600, 20601,\n",
       "       20602, 20603, 20604, 20605, 20606, 20609, 20611, 20612, 20614,\n",
       "       20615, 20617, 20620, 20621, 20622, 20623, 20624, 20627, 20628,\n",
       "       20629, 20632, 20633, 20636, 20637, 20638, 20639, 20640, 20641,\n",
       "       20642, 20644, 20646, 20647, 20649, 20651, 20652, 20653, 20654,\n",
       "       20655, 20657, 20658, 20659, 20660, 20661, 20662, 20663, 20664,\n",
       "       20666, 20667, 20670, 20672, 20673, 20674, 20676, 20677, 20678,\n",
       "       20679, 20680, 20681, 20682, 20684, 20685, 20686, 20689, 20691,\n",
       "       20693, 20694, 20696, 20697, 20699, 20700, 20701, 20702, 20703,\n",
       "       20705, 20706, 20708, 20709, 20711, 20713, 20714, 20715, 20719,\n",
       "       20720, 20721, 20724, 20729, 20730, 20732, 20733, 20735, 20737,\n",
       "       20739, 20741, 20742, 20743, 20744, 20745, 20746, 20749, 20750,\n",
       "       20751, 20754, 20756, 20757, 20758, 20759, 20761, 20762, 20765,\n",
       "       20768, 20771, 20772, 20773, 20774, 20775, 20777, 20781, 20783,\n",
       "       20785, 20786, 20788, 20789, 20793, 20795, 20800, 20801, 20802,\n",
       "       20803, 20807, 20809, 20810, 20811, 20812, 20815, 20817, 20818,\n",
       "       20820, 20822, 20823, 20824, 20826, 20827, 20828, 20830, 20831,\n",
       "       20832, 20835, 20838, 20840, 20843, 20845, 20846, 20847, 20849,\n",
       "       20852, 20853, 20855, 20859, 20862, 20863, 20864, 20865, 20870,\n",
       "       20877, 20878, 20879, 20882, 20883, 20885, 20886, 20892, 20894,\n",
       "       20899, 20901, 20902, 20904, 20906, 20907, 20908, 20910, 20912,\n",
       "       20913, 20914, 20917, 20919, 20920, 20922, 20924, 20925, 20927,\n",
       "       20928, 20931, 20932, 20933, 20936, 20937, 20941, 20942, 20945,\n",
       "       20946, 20947, 20948, 20949, 20951, 20953, 20956, 20957, 20961,\n",
       "       20962, 20965, 20966, 20967, 20968, 20970, 20975, 20976, 20982,\n",
       "       20985, 20986, 20987, 20990, 20991, 20994, 20995, 20996, 20997,\n",
       "       21001, 21003, 21006, 21007, 21008, 21014, 21016, 21022, 21024,\n",
       "       21027, 21028, 21032, 21033, 21034, 21035, 21037, 21038, 21039,\n",
       "       21040, 21042, 21044, 21048, 21049, 21055, 21056, 21057, 21058,\n",
       "       21064, 21065, 21073, 21074, 21077, 21079, 21080, 21084, 21086,\n",
       "       21087, 21088, 21092, 21093, 21097, 21099, 21105, 21109, 21110,\n",
       "       21111, 21112, 21114, 21118, 21119, 21126, 21129, 21131, 21135,\n",
       "       21140, 21142, 21144, 21146, 21153, 21154, 21155, 21157, 21159,\n",
       "       21163, 21164, 21167, 21168, 21170, 21171, 21176, 21179, 21180,\n",
       "       21182, 21184, 21190, 21191, 21192, 21194, 21196, 21200, 21201,\n",
       "       21202, 21207, 21209, 21212, 21214, 21218, 21222, 21224, 21226,\n",
       "       21227, 21233, 21244, 21245, 21246, 21248, 21252, 21256, 21259,\n",
       "       21262, 21263, 21265, 21266, 21267, 21276])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_id_a_predecir = pd.read_csv('product_id_apredecir201912.txt', sep='\\t')['product_id'].unique()\n",
    "product_id_a_predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12254054 entries, 0 to 19250837\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Dtype    \n",
      "---  ------                 -----    \n",
      " 0   product_id             int64    \n",
      " 1   fecha                  period[M]\n",
      " 2   customer_id            category \n",
      " 3   periodo                float64  \n",
      " 4   plan_precios_cuidados  category \n",
      " 5   cust_request_qty       float64  \n",
      " 6   cust_request_tn        float32  \n",
      " 7   tn                     float32  \n",
      " 8   stock_final            float64  \n",
      " 9   cat1                   object   \n",
      " 10  cat2                   object   \n",
      " 11  cat3                   object   \n",
      " 12  brand                  object   \n",
      " 13  sku_size               float64  \n",
      " 14  target                 float32  \n",
      "dtypes: category(2), float32(3), float64(4), int64(1), object(4), period[M](1)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "# filtrar df por product_id_a_predecir\n",
    "df = df[df['product_id'].isin(product_id_a_predecir)]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>fecha</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>stock_final</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>10001</td>\n",
       "      <td>201701.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>99.438606</td>\n",
       "      <td>99.438606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>92.465370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>10001</td>\n",
       "      <td>201702.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>198.843643</td>\n",
       "      <td>198.843643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>13.297280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>10001</td>\n",
       "      <td>201703.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>92.465370</td>\n",
       "      <td>92.465370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>101.005630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>10001</td>\n",
       "      <td>201704.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.297280</td>\n",
       "      <td>13.297280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>128.047913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-05</td>\n",
       "      <td>10001</td>\n",
       "      <td>201705.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>101.207108</td>\n",
       "      <td>101.005630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>101.207108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19250833</th>\n",
       "      <td>21276</td>\n",
       "      <td>2019-08</td>\n",
       "      <td>10637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>PIEL1</td>\n",
       "      <td>Cara</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19250834</th>\n",
       "      <td>21276</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>10637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>PIEL1</td>\n",
       "      <td>Cara</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19250835</th>\n",
       "      <td>21276</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>10637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>PIEL1</td>\n",
       "      <td>Cara</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19250836</th>\n",
       "      <td>21276</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>10637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>PIEL1</td>\n",
       "      <td>Cara</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19250837</th>\n",
       "      <td>21276</td>\n",
       "      <td>2019-12</td>\n",
       "      <td>10637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>PIEL1</td>\n",
       "      <td>Cara</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12254054 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          product_id    fecha customer_id   periodo plan_precios_cuidados  \\\n",
       "0              20001  2017-01       10001  201701.0                     0   \n",
       "1              20001  2017-02       10001  201702.0                     0   \n",
       "2              20001  2017-03       10001  201703.0                     0   \n",
       "3              20001  2017-04       10001  201704.0                     0   \n",
       "4              20001  2017-05       10001  201705.0                     0   \n",
       "...              ...      ...         ...       ...                   ...   \n",
       "19250833       21276  2019-08       10637       NaN                   NaN   \n",
       "19250834       21276  2019-09       10637       NaN                   NaN   \n",
       "19250835       21276  2019-10       10637       NaN                   NaN   \n",
       "19250836       21276  2019-11       10637       NaN                   NaN   \n",
       "19250837       21276  2019-12       10637       NaN                   NaN   \n",
       "\n",
       "          cust_request_qty  cust_request_tn          tn  stock_final cat1  \\\n",
       "0                     11.0        99.438606   99.438606          NaN   HC   \n",
       "1                     23.0       198.843643  198.843643          NaN   HC   \n",
       "2                     33.0        92.465370   92.465370          NaN   HC   \n",
       "3                      8.0        13.297280   13.297280          NaN   HC   \n",
       "4                     15.0       101.207108  101.005630          NaN   HC   \n",
       "...                    ...              ...         ...          ...  ...   \n",
       "19250833               0.0         0.000000    0.000000          NaN   PC   \n",
       "19250834               0.0         0.000000    0.000000          NaN   PC   \n",
       "19250835               0.0         0.000000    0.000000          NaN   PC   \n",
       "19250836               0.0         0.000000    0.000000          NaN   PC   \n",
       "19250837               0.0         0.000000    0.000000          NaN   PC   \n",
       "\n",
       "                 cat2     cat3  brand  sku_size      target  \n",
       "0         ROPA LAVADO  Liquido  ARIEL    3000.0   92.465370  \n",
       "1         ROPA LAVADO  Liquido  ARIEL    3000.0   13.297280  \n",
       "2         ROPA LAVADO  Liquido  ARIEL    3000.0  101.005630  \n",
       "3         ROPA LAVADO  Liquido  ARIEL    3000.0  128.047913  \n",
       "4         ROPA LAVADO  Liquido  ARIEL    3000.0  101.207108  \n",
       "...               ...      ...    ...       ...         ...  \n",
       "19250833        PIEL1     Cara  NIVEA     140.0    0.000000  \n",
       "19250834        PIEL1     Cara  NIVEA     140.0    0.000000  \n",
       "19250835        PIEL1     Cara  NIVEA     140.0    0.000000  \n",
       "19250836        PIEL1     Cara  NIVEA     140.0         NaN  \n",
       "19250837        PIEL1     Cara  NIVEA     140.0         NaN  \n",
       "\n",
       "[12254054 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformo plan_precios_cuidados a bool (True si > 0  )\n",
    "df = pd.read_parquet('df_intermedio.parquet')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformar product_id y customer_id a category\n",
    "df['product_id'] = df['product_id'].astype('category')\n",
    "df['customer_id'] = df['customer_id'].astype('category')\n",
    "#borro periodo\n",
    "df = df.drop(columns=['periodo'])\n",
    "# paso cust_request_qty a int32\n",
    "df['cust_request_qty'] = df['cust_request_qty'].astype('int32')\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = crear_features(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar archivo como parquet para que conserve el tipo de dato\n",
    "df.to_parquet('df.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_parquet('df.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_df es product_id 20001 customer_id 10010\n",
    "sub_df = df[(df['product_id'] == 20001) & (df['customer_id'] == 10010)]\n",
    "print(sub_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformar product_id y customer_id a category\n",
    "df['product_id'] = df['product_id'].astype('category')\n",
    "df['customer_id'] = df['customer_id'].astype('category')\n",
    "# paso mes y year a uint16\n",
    "df['mes'] = df['mes'].astype('uint16')\n",
    "df['year'] = df['year'].astype('uint16')\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazar todos los float64 por float32\n",
    "for col in df.select_dtypes(include=['float64']).columns:\n",
    "    df[col] = df[col].astype('float32')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtengo producto 20001 customer_id 10001 tn y target\n",
    "df[df['product_id'] == 20001][df['customer_id'] == 10006][['tn', 'target']].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Separar dataset\n",
    "train, eval_data, test, kaggle_pred = separar_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seleccionar columnas para el modelo (excluyendo variables no numéricas y target)\n",
    "\n",
    "# Seleccionar columnas para el modelo (incluyendo variables categóricas e identificadores)\n",
    "columnas_modelo = [col for col in train.columns if col not in \n",
    "                   ['periodo', 'periodo_original', 'fecha', 'target', \n",
    "                    'fecha_origen', 'primera_compra']]\n",
    "\n",
    "# 7) Entrenar modelo con train+eval\n",
    "X_train = pd.concat([train[columnas_modelo], eval_data[columnas_modelo]])\n",
    "y_train = pd.concat([train['target'], eval_data['target']])\n",
    "\n",
    "X_eval = eval_data[columnas_modelo]\n",
    "y_eval = eval_data['target']\n",
    "\n",
    "X_test = test[columnas_modelo]\n",
    "y_test = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar primer modelo usando nuestra métrica personalizada\n",
    "# silence FutureWarnings of pandas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "modelo = entrenar_modelo(X_train, y_train, X_eval, y_eval, eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Evaluar en test\n",
    "eval_df,error_test = evaluar_modelo(modelo, X_test, y_test, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar features importantes\n",
    "lgb.plot_importance(modelo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 9) Reentrenar con más datos\n",
    "X_train_final = pd.concat([train[columnas_modelo], eval_data[columnas_modelo], test[columnas_modelo]])\n",
    "y_train_final = pd.concat([train['target'], eval_data['target'], test['target']])\n",
    "\n",
    "# Para el entrenamiento final, usamos test como conjunto de evaluación\n",
    "modelo_final = entrenar_modelo(X_train_final, y_train_final, X_test, y_test, test)\n",
    "\n",
    "# 10) Predecir para Kaggle y preparar submission\n",
    "X_kaggle = kaggle_pred[columnas_modelo]\n",
    "kaggle_pred['tn_predicha'] = modelo_final.predict(X_kaggle)\n",
    "\n",
    "# Agrupar por product_id para la submission\n",
    "submission = kaggle_pred.groupby('product_id')['tn_predicha'].sum().reset_index()\n",
    "submission.columns = ['product_id', 'tn']\n",
    "\n",
    "# Guardar archivo de submission\n",
    "submission.to_csv(f'submission_{error_test}.csv', index=False)\n",
    "print(\"Archivo de submission generado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_dos_etapas(X_train, y_train, X_eval, y_eval, df_eval):\n",
    "    # Primera etapa: Clasificador para predecir si será cero o no\n",
    "    y_train_binary = (y_train > 0).astype(int)\n",
    "    y_eval_binary = (y_eval > 0).astype(int)\n",
    "    \n",
    "    # Entrenar clasificador\n",
    "    params_clf = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 31,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    train_data_clf = lgb.Dataset(X_train, label=y_train_binary)\n",
    "    eval_data_clf = lgb.Dataset(X_eval, label=y_eval_binary, reference=train_data_clf)\n",
    "    \n",
    "    \n",
    "    model_clf = lgb.train(\n",
    "        params_clf,\n",
    "        train_data_clf,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[eval_data_clf],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
    "    )\n",
    "    \n",
    "    # Segunda etapa: Regresor para todos los casos\n",
    "    params_reg = {\n",
    "        'objective': 'regression',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 31,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    train_data_reg = lgb.Dataset(X_train, label=y_train)\n",
    "    eval_data_reg = lgb.Dataset(X_eval, label=y_eval, reference=train_data_reg)\n",
    "    \n",
    "    # Métrica custom para regresión\n",
    "    custom_metric_reg = CustomMetric(df_eval[['product_id']].copy())\n",
    "    \n",
    "    model_reg = lgb.train(\n",
    "        params_reg,\n",
    "        train_data_reg,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[eval_data_reg],\n",
    "        feval=custom_metric_reg,\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
    "    )\n",
    "    \n",
    "    return model_clf, model_reg\n",
    "\n",
    "def evaluar_modelo_dos_etapas(model_clf, model_reg, X_test, y_test, test_df):\n",
    "    # Primera etapa: Predecir probabilidad de ser no cero\n",
    "    prob_non_zero = model_clf.predict(X_test)\n",
    "    \n",
    "    # Segunda etapa: Predecir valor para todos los casos\n",
    "    predictions_reg = model_reg.predict(X_test)\n",
    "    \n",
    "    # Combinar predicciones: si la probabilidad de ser no cero es baja, forzar a cero\n",
    "    predictions = np.where(prob_non_zero > 0.5, predictions_reg, 0)\n",
    "    test_df['predictions'] = predictions\n",
    "    \n",
    "    # Error por producto\n",
    "    product_actual = test_df.groupby('product_id')['target'].sum()\n",
    "    product_pred = test_df.groupby('product_id')['predictions'].sum()\n",
    "    \n",
    "    # Crear DataFrame de evaluación\n",
    "    eval_df = pd.DataFrame({\n",
    "        'product_id': product_actual.index,\n",
    "        'tn_real': product_actual.values,\n",
    "        'tn_predicha': product_pred.values\n",
    "    })\n",
    "    \n",
    "    # Calcular el error personalizado\n",
    "    total_error = np.sum(np.abs(eval_df['tn_real'] - eval_df['tn_predicha'])) / np.sum(eval_df['tn_real'])\n",
    "    \n",
    "    print(f\"Error en test: {total_error:.4f}\")\n",
    "    print(\"\\nTop 5 productos con mayor error absoluto:\")\n",
    "    eval_df['error_absoluto'] = np.abs(eval_df['tn_real'] - eval_df['tn_predicha'])\n",
    "    print(eval_df.sort_values('error_absoluto', ascending=False).head())\n",
    "    \n",
    "    # Métricas adicionales\n",
    "    print(\"\\nMétricas adicionales:\")\n",
    "    print(f\"Porcentaje de ceros reales: {(eval_df['tn_real'] == 0).mean()*100:.2f}%\")\n",
    "    print(f\"Porcentaje de ceros predichos: {(eval_df['tn_predicha'] == 0).mean()*100:.2f}%\")\n",
    "    \n",
    "    # Error solo en casos no cero\n",
    "    mask_non_zero = eval_df['tn_real'] > 0\n",
    "    error_non_zero = np.sum(np.abs(eval_df.loc[mask_non_zero, 'tn_real'] - \n",
    "                                  eval_df.loc[mask_non_zero, 'tn_predicha'])) / \\\n",
    "                     np.sum(eval_df.loc[mask_non_zero, 'tn_real'])\n",
    "    print(f\"Error en casos no cero: {error_non_zero:.4f}\")\n",
    "    \n",
    "    return eval_df, total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelos\n",
    "model_clf, model_reg = entrenar_modelo_dos_etapas(X_train, y_train, X_eval, y_eval, eval_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df, total_error = evaluar_modelo_dos_etapas(model_clf, model_reg, X_test, y_test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model_clf)\n",
    "lgb.plot_importance(model_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Reentrenar con más datos\n",
    "X_train_final = pd.concat([train[columnas_modelo], eval_data[columnas_modelo], test[columnas_modelo]])\n",
    "y_train_final = pd.concat([train['target'], eval_data['target'], test['target']])\n",
    "\n",
    "# Para el entrenamiento final, usamos test como conjunto de evaluación\n",
    "modelo_clf_final, modelo_reg_final = entrenar_modelo_dos_etapas(X_train_final, y_train_final, X_test, y_test, test)\n",
    "\n",
    "# 10) Predecir para Kaggle y preparar submission\n",
    "X_kaggle = kaggle_pred[columnas_modelo]\n",
    "\n",
    "# Primera etapa: Predecir probabilidad de ser no cero\n",
    "prob_non_zero = modelo_clf_final.predict(X_kaggle)\n",
    "\n",
    "# Segunda etapa: Predecir valor\n",
    "predictions_reg = modelo_reg_final.predict(X_kaggle)\n",
    "\n",
    "# Combinar predicciones: si la probabilidad de ser no cero es baja, forzar a cero\n",
    "kaggle_pred['tn_predicha'] = np.where(prob_non_zero > 0.5, predictions_reg, 0)\n",
    "\n",
    "# Agrupar por product_id para la submission\n",
    "submission = kaggle_pred.groupby('product_id')['tn_predicha'].sum().reset_index()\n",
    "submission.columns = ['product_id', 'tn']\n",
    "\n",
    "# Guardar archivo de submission\n",
    "submission.to_csv(f'submission_{total_error}_2_etapas.csv', index=False)\n",
    "print(\"Archivo de submission generado correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labo3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
