{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import Pipeline\n",
    "from pipeline.steps import *\n",
    "\n",
    "pipeline_fe = Pipeline(\n",
    "    steps=[\n",
    "        LoadDataFrameStep(\"df_intermedio.parquet\"),\n",
    "        FilterProductForTestingStep(total_products_ids=1, random=False),\n",
    "\n",
    "        CreateSerieIdStep(),\n",
    "        DateRelatedFeaturesStep(),\n",
    "        CastDataTypesStep(dtypes=\n",
    "            {\n",
    "                \"product_id\": \"uint32\", \n",
    "                \"customer_id\": \"uint32\",\n",
    "                \"mes\": \"uint16\",\n",
    "                \"year\": \"uint16\",\n",
    "                \"brand\": \"category\",\n",
    "                \"cat1\": \"category\",\n",
    "                \"cat2\": \"category\",\n",
    "                \"cat3\": \"category\",\n",
    "            }\n",
    "        ),\n",
    "\n",
    "        ReduceMemoryUsageStep(),\n",
    "        SaveDataFrameStep(df_name=\"df\", file_name=\"df_tsfresh_base.pickle\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing step: LoadDataFrameStep\n",
      "Step LoadDataFrameStep completed in 2.59 seconds\n",
      "Executing step: FilterProductForTestingStep\n",
      "Filtered DataFrame shape: (17862, 13)\n",
      "Step FilterProductForTestingStep completed in 0.56 seconds\n"
     ]
    }
   ],
   "source": [
    "pipeline_fe = Pipeline(\n",
    "    steps=[\n",
    "        LoadDataFrameStep(\"df_intermedio.parquet\"),\n",
    "        FilterProductForTestingStep(total_products_ids=1, random=False),\n",
    "\n",
    "    ]\n",
    ")\n",
    "pipeline_fe.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>fecha</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>stock_final</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>10001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>99.438606</td>\n",
       "      <td>99.438606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>10001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>198.843643</td>\n",
       "      <td>198.843643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>10001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>92.465370</td>\n",
       "      <td>92.465370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>10001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>13.297280</td>\n",
       "      <td>13.297280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-05</td>\n",
       "      <td>10001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>101.207108</td>\n",
       "      <td>101.005630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17857</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>10635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17858</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>10635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17859</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>10635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17860</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>10636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17861</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>10637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17862 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id    fecha  customer_id  plan_precios_cuidados  \\\n",
       "0           20001  2017-01        10001                    0.0   \n",
       "1           20001  2017-02        10001                    0.0   \n",
       "2           20001  2017-03        10001                    0.0   \n",
       "3           20001  2017-04        10001                    0.0   \n",
       "4           20001  2017-05        10001                    0.0   \n",
       "...           ...      ...          ...                    ...   \n",
       "17857       20001  2017-01        10635                    0.0   \n",
       "17858       20001  2017-02        10635                    0.0   \n",
       "17859       20001  2017-03        10635                    0.0   \n",
       "17860       20001  2017-02        10636                    0.0   \n",
       "17861       20001  2017-09        10637                    0.0   \n",
       "\n",
       "       cust_request_qty  cust_request_tn          tn  stock_final cat1  \\\n",
       "0                    11        99.438606   99.438606          NaN   HC   \n",
       "1                    23       198.843643  198.843643          NaN   HC   \n",
       "2                    33        92.465370   92.465370          NaN   HC   \n",
       "3                     8        13.297280   13.297280          NaN   HC   \n",
       "4                    15       101.207108  101.005630          NaN   HC   \n",
       "...                 ...              ...         ...          ...  ...   \n",
       "17857                 0         0.000000    0.000000          NaN   HC   \n",
       "17858                 0         0.000000    0.000000          NaN   HC   \n",
       "17859                 0         0.000000    0.000000          NaN   HC   \n",
       "17860                 0         0.000000    0.000000          NaN   HC   \n",
       "17861                 0         0.000000    0.000000          NaN   HC   \n",
       "\n",
       "              cat2     cat3  brand  sku_size  \n",
       "0      ROPA LAVADO  Liquido  ARIEL    3000.0  \n",
       "1      ROPA LAVADO  Liquido  ARIEL    3000.0  \n",
       "2      ROPA LAVADO  Liquido  ARIEL    3000.0  \n",
       "3      ROPA LAVADO  Liquido  ARIEL    3000.0  \n",
       "4      ROPA LAVADO  Liquido  ARIEL    3000.0  \n",
       "...            ...      ...    ...       ...  \n",
       "17857  ROPA LAVADO  Liquido  ARIEL    3000.0  \n",
       "17858  ROPA LAVADO  Liquido  ARIEL    3000.0  \n",
       "17859  ROPA LAVADO  Liquido  ARIEL    3000.0  \n",
       "17860  ROPA LAVADO  Liquido  ARIEL    3000.0  \n",
       "17861  ROPA LAVADO  Liquido  ARIEL    3000.0  \n",
       "\n",
       "[17862 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipeline_fe.get_artifact(\"df\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported Type Index",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsflex\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeatures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultipleFeatureDescriptors, FeatureCollection\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Asegúrate de que 'fecha' sea datetime y ordena\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mfecha\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfecha\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_timestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m df = df.sort_values([\u001b[33m'\u001b[39m\u001b[33mcustomer_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfecha\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Pivot: convertir a lista de DataFrames por cliente\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/labo3/lib/python3.12/site-packages/pandas/core/series.py:5983\u001b[39m, in \u001b[36mSeries.to_timestamp\u001b[39m\u001b[34m(self, freq, how, copy)\u001b[39m\n\u001b[32m   5924\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5925\u001b[39m \u001b[33;03mCast to DatetimeIndex of Timestamps, at *beginning* of period.\u001b[39;00m\n\u001b[32m   5926\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5980\u001b[39m \u001b[33;03mFreq: YE-JAN, dtype: int64\u001b[39;00m\n\u001b[32m   5981\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5982\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.index, PeriodIndex):\n\u001b[32m-> \u001b[39m\u001b[32m5983\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33munsupported Type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.index).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   5985\u001b[39m new_obj = \u001b[38;5;28mself\u001b[39m.copy(deep=copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write())\n\u001b[32m   5986\u001b[39m new_index = \u001b[38;5;28mself\u001b[39m.index.to_timestamp(freq=freq, how=how)\n",
      "\u001b[31mTypeError\u001b[39m: unsupported Type Index"
     ]
    }
   ],
   "source": [
    "from tsfresh.utilities.dataframe_functions import roll_time_series\n",
    "from tsfresh.feature_extraction import EfficientFCParameters, MinimalFCParameters\n",
    "\n",
    "rolled_backward = roll_time_series(activity_data,\n",
    "                                           column_id=id_column,\n",
    "                                           column_sort=sort_column,\n",
    "                                           column_kind=None,\n",
    "                                           rolling_direction=1,\n",
    "                                           max_timeshift=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing step: LoadDataFrameFromPickleStep\n",
      "Step LoadDataFrameFromPickleStep completed in 0.04 seconds\n",
      "Executing step: SplitDataFrameStep\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'fecha'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/labo3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'fecha'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m      1\u001b[39m model_test_pipeline = Pipeline(\n\u001b[32m      2\u001b[39m     steps=[\n\u001b[32m      3\u001b[39m         LoadDataFrameFromPickleStep(path=\u001b[33m\"\u001b[39m\u001b[33mdf_tsfresh_base.pickle\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     ]\n\u001b[32m     25\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mmodel_test_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programacion/labo3/pipeline/base.py:342\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, verbose, last_step_callback)\u001b[39m\n\u001b[32m    340\u001b[39m start_time = time.time()\n\u001b[32m    341\u001b[39m params = \u001b[38;5;28mself\u001b[39m.__fill_params_from_step(step)\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m artifacts_to_save = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m artifacts_to_save \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    344\u001b[39m     artifacts_to_save = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programacion/labo3/pipeline/steps/df_setup.py:20\u001b[39m, in \u001b[36mSplitDataFrameStep.execute\u001b[39m\u001b[34m(self, pipeline)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, pipeline) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     19\u001b[39m     df = pipeline.get_artifact(\u001b[38;5;28mself\u001b[39m.df)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     test_df = df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfecha\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[38;5;28mself\u001b[39m.test_date]\n\u001b[32m     21\u001b[39m     train_df = df[df[\u001b[33m\"\u001b[39m\u001b[33mfecha\u001b[39m\u001b[33m\"\u001b[39m] < \u001b[38;5;28mself\u001b[39m.test_date]\n\u001b[32m     22\u001b[39m     last_train_date = train_df[\u001b[33m\"\u001b[39m\u001b[33mfecha\u001b[39m\u001b[33m\"\u001b[39m].max()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/labo3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/labo3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'fecha'"
     ]
    }
   ],
   "source": [
    "model_test_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        LoadDataFrameFromPickleStep(path=\"df_tsfresh_base.pickle\"),\n",
    "        SplitDataFrameStep(df=\"df\", test_date=\"2019-10\", gap=1),\n",
    "        CreateTargetColumStep(target_col=\"tn\"),\n",
    "        #CreateMultiDiffTargetColumStep(target_col=tn),\n",
    "        #CreateTargetColumDiffStep(target_col=tn),\n",
    "        ScaleFeatureStep(column=\".*tn.*\", override=False, regex=True),  \n",
    "        ScaleFeatureStep(column=\"target\", override=True, scaler=PipelineMinMaxScaler),\n",
    "        ReduceMemoryUsageStep(),\n",
    "        PrepareXYStep(),\n",
    "        #TrainModelStep(model_cls=XGBOOSTPipelineModel, params=xgb_params),\n",
    "        #TrainModelStep(model_cls=MLPPipelineModel),\n",
    "        TrainModelStep(folds=0, params={'num_leaves': 31, \"n_estimators\": 1200, \"learning_rate\": 0.01}),\n",
    "        #TrainNNModelStep(model_cls=NNPipelineModel),\n",
    "        #TrainModelStep(folds=0, params={'num_leaves': 31, \"n_estimators\": 200, \"learning_rate\": 0.1}),\n",
    "        PredictStep(),\n",
    "        #PredictNNModelStep(),\n",
    "        InverseScalePredictionsStep(),\n",
    "        IntegratePredictionsStep(),\n",
    "        EvaluatePredictionsSteps(),\n",
    "        PlotFeatureImportanceStep(),\n",
    "        #SaveExperimentStep(exp_name=\"test_model\",),\n",
    "    ]\n",
    ")\n",
    "model_test_pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labo3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
